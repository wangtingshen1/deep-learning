{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "original_dataset_dir_female = '/home/wangtingshen/tingshen-code/female/'\n",
    "original_dataset_dir_male = '/home/wangtingshen/tingshen-code/male/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存较小的数据集\n",
    "base_dir = '/home/wangtingshen/tingshen-code/real-dataset'\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拼接子路径，划分训练、验证、测试集\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练女性图像目录\n",
    "train_female_dir = os.path.join(train_dir,'female')\n",
    "os.mkdir(train_female_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练男性图像目录\n",
    "train_male_dir = os.path.join(train_dir,'male')\n",
    "os.mkdir(train_male_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证女性图像目录\n",
    "validation_female_dir = os.path.join(validation_dir,'female')\n",
    "os.mkdir(validation_female_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证男性图像目录\n",
    "validation_male_dir = os.path.join(validation_dir,'male')\n",
    "os.mkdir(validation_male_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试女性图像目录\n",
    "test_female_dir = os.path.join(test_dir,'female')\n",
    "os.mkdir(test_female_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试男性图像目录\n",
    "test_male_dir = os.path.join(test_dir,'male')\n",
    "os.mkdir(test_male_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将前70000张女性复制到train_female_dir\n",
    "fnames = ['female.{}.jpg'.format(i+1) for i in range(70000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir_female, fname)\n",
    "    dst = os.path.join(train_female_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将前5000张女性复制到validation_female_dir\n",
    "fnames = ['female.{}.jpg'.format(i+1) for i in range(70000,75000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir_female, fname)\n",
    "    dst = os.path.join(validation_female_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将前5000张女性复制到test_female_dir\n",
    "fnames = ['female.{}.jpg'.format(i+1) for i in range(75000,80000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir_female, fname)\n",
    "    dst = os.path.join(test_female_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将前70000张男性复制到train_male_dir\n",
    "fnames = ['male.{}.jpg'.format(i+1) for i in range(70000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir_male, fname)\n",
    "    dst = os.path.join(train_male_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将前5000张男性复制到validation_male_dir\n",
    "fnames = ['male.{}.jpg'.format(i+1) for i in range(70000,75000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir_male, fname)\n",
    "    dst = os.path.join(validation_male_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将前5000张男性复制到test_male_dir\n",
    "fnames = ['male.{}.jpg'.format(i+1) for i in range(75000,80000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir_male, fname)\n",
    "    dst = os.path.join(test_male_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training female images: 70000\n",
      "total training male images: 70000\n",
      "total validation female images: 5000\n",
      "total validation male images: 5000\n",
      "total test female images: 5000\n",
      "total test male images: 5000\n"
     ]
    }
   ],
   "source": [
    "print('total training female images:',len(os.listdir(train_female_dir)))\n",
    "print('total training male images:',len(os.listdir(train_male_dir)))\n",
    "print('total validation female images:',len(os.listdir(validation_female_dir)))\n",
    "print('total validation male images:',len(os.listdir(validation_male_dir)))\n",
    "print('total test female images:',len(os.listdir(test_female_dir)))\n",
    "print('total test male images:',len(os.listdir(test_male_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#默认打乱数据\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224,224),\n",
    "        batch_size=35,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(224,224),\n",
    "        batch_size=35,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (35, 224, 224, 3)\n",
      "labels batch shape: (35,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPool2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# 定义输入\n",
    "input_shape = (224,224,3) # RGB影像224x224（height,width,channel)\n",
    "\n",
    "model = models.Sequential()\n",
    "# 第1个卷积区块(block1)\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu',input_shape=input_shape,name='block1_conv1'))\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu',name='block1_conv2'))\n",
    "model.add(MaxPool2D((2,2),strides=(2,2),name='block1_pool'))\n",
    "\n",
    "# 第2个卷积区块(block2)\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu',name='block2_conv1'))\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu',name='block2_conv2'))\n",
    "model.add(MaxPool2D((2,2),strides=(2,2),name='block2_pool'))\n",
    "\n",
    "# 第3个区块(block3)\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu',name='block3_conv1'))\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu',name='block3_conv2'))\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu',name='block3_conv3'))\n",
    "model.add(MaxPool2D((2,2),strides=(2,2),name='block3_pool'))\n",
    "\n",
    "# 第4个区块(block4)\n",
    "model.add(Conv2D(512,(3,3),padding='same',activation='relu',name='block4_conv1'))\n",
    "model.add(Conv2D(512,(3,3),padding='same',activation='relu',name='block4_conv2'))\n",
    "model.add(Conv2D(512,(3,3),padding='same',activation='relu',name='block4_conv3'))\n",
    "model.add(MaxPool2D((2,2),strides=(2,2),name='block4_pool'))\n",
    "\n",
    "# 第5个区块(block5)\n",
    "model.add(Conv2D(512,(3,3),padding='same',activation='relu',name='block5_conv1'))\n",
    "model.add(Conv2D(512,(3,3),padding='same',activation='relu',name='block5_conv2'))\n",
    "model.add(Conv2D(512,(3,3),padding='same',activation='relu',name='block5_conv3'))\n",
    "model.add(MaxPool2D((2,2),strides=(2,2),name='block5_pool'))\n",
    "\n",
    "# 前馈全连接区块\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(4096,activation='relu',name='fc1'))\n",
    "model.add(Dense(4096,activation='relu',name='fc2'))\n",
    "model.add(Dense(1,activation='sigmoid',name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 134,264,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 517s 258ms/step - loss: 0.2672 - acc: 0.8791 - val_loss: 0.3325 - val_acc: 0.9451\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 503s 252ms/step - loss: 0.1185 - acc: 0.9588 - val_loss: 0.4205 - val_acc: 0.9674\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 505s 253ms/step - loss: 0.0987 - acc: 0.9664 - val_loss: 0.0620 - val_acc: 0.9737\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.0919 - acc: 0.9689 - val_loss: 0.3200 - val_acc: 0.9669\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 510s 255ms/step - loss: 0.0842 - acc: 0.9717 - val_loss: 0.0677 - val_acc: 0.9691\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 517s 259ms/step - loss: 0.0857 - acc: 0.9729 - val_loss: 0.1500 - val_acc: 0.9529\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 517s 259ms/step - loss: 0.0813 - acc: 0.9747 - val_loss: 0.0254 - val_acc: 0.9766\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 519s 259ms/step - loss: 0.0826 - acc: 0.9745 - val_loss: 0.0033 - val_acc: 0.9703\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 523s 261ms/step - loss: 2.1293 - acc: 0.9752 - val_loss: 3.8510e-04 - val_acc: 0.9811\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 526s 263ms/step - loss: 0.0785 - acc: 0.9760 - val_loss: 0.0414 - val_acc: 0.9771\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 529s 265ms/step - loss: 0.0784 - acc: 0.9775 - val_loss: 0.1068 - val_acc: 0.9754\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 532s 266ms/step - loss: 0.0808 - acc: 0.9757 - val_loss: 0.0363 - val_acc: 0.9793\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 535s 268ms/step - loss: 0.0783 - acc: 0.9764 - val_loss: 0.0038 - val_acc: 0.9789\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 0.0914 - acc: 0.9764 - val_loss: 0.0914 - val_acc: 0.9634\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 535s 267ms/step - loss: 0.0788 - acc: 0.9760 - val_loss: 0.0333 - val_acc: 0.9623\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 0.0994 - acc: 0.9763 - val_loss: 0.1442 - val_acc: 0.9577\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 0.1011 - acc: 0.9764 - val_loss: 0.0063 - val_acc: 0.9691\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 0.0978 - acc: 0.9761 - val_loss: 0.0148 - val_acc: 0.9747\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.2264 - acc: 0.9766 - val_loss: 0.0586 - val_acc: 0.9737\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.0947 - acc: 0.9763 - val_loss: 0.1653 - val_acc: 0.9651\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.0798 - acc: 0.9775 - val_loss: 0.0697 - val_acc: 0.9691\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 0.0961 - acc: 0.9761 - val_loss: 0.0032 - val_acc: 0.9817\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 0.1395 - acc: 0.9776 - val_loss: 0.0037 - val_acc: 0.9730\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 0.0879 - acc: 0.9771 - val_loss: 0.0073 - val_acc: 0.9703\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 1.4041 - acc: 0.9767 - val_loss: 0.0239 - val_acc: 0.9703\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 0.1131 - acc: 0.9766 - val_loss: 0.1619 - val_acc: 0.9789\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.0977 - acc: 0.9756 - val_loss: 1.4567 - val_acc: 0.9794\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.0849 - acc: 0.9747 - val_loss: 0.0182 - val_acc: 0.9680\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.2573 - acc: 0.9755 - val_loss: 7.2672e-05 - val_acc: 0.9747\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 537s 268ms/step - loss: 0.1197 - acc: 0.9762 - val_loss: 0.0146 - val_acc: 0.9731\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 0.5671 - acc: 0.9763 - val_loss: 0.0034 - val_acc: 0.9737\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 0.0857 - acc: 0.9753 - val_loss: 0.0720 - val_acc: 0.9777\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 2.2061 - acc: 0.9755 - val_loss: 0.0109 - val_acc: 0.9720\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 536s 268ms/step - loss: 2.9339 - acc: 0.9750 - val_loss: 0.4465 - val_acc: 0.9703\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1355 - acc: 0.9773 - val_loss: 5.0099e-04 - val_acc: 0.9833\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.0876 - acc: 0.9757 - val_loss: 0.0555 - val_acc: 0.9651\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.2735 - acc: 0.9765 - val_loss: 0.0985 - val_acc: 0.9806\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 4.4657 - acc: 0.9739 - val_loss: 0.0266 - val_acc: 0.9737\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 514s 257ms/step - loss: 0.1356 - acc: 0.9756 - val_loss: 0.0513 - val_acc: 0.9714\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 514s 257ms/step - loss: 0.1072 - acc: 0.9750 - val_loss: 0.0730 - val_acc: 0.9709\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.0899 - acc: 0.9750 - val_loss: 0.0400 - val_acc: 0.9655\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1022 - acc: 0.9728 - val_loss: 0.7217 - val_acc: 0.9731\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1609 - acc: 0.9707 - val_loss: 0.0911 - val_acc: 0.9417\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 2.0583 - acc: 0.9730 - val_loss: 0.3397 - val_acc: 0.9434\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1081 - acc: 0.9727 - val_loss: 2.4980e-04 - val_acc: 0.9806\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 1.6023 - acc: 0.9744 - val_loss: 0.0883 - val_acc: 0.9713\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1305 - acc: 0.9743 - val_loss: 0.0398 - val_acc: 0.9766\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1217 - acc: 0.9736 - val_loss: 0.2145 - val_acc: 0.9783\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 0.1326 - acc: 0.9716 - val_loss: 0.0381 - val_acc: 0.9566\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 513s 256ms/step - loss: 0.1527 - acc: 0.9715 - val_loss: 0.0776 - val_acc: 0.9754\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 513s 256ms/step - loss: 0.2479 - acc: 0.9721 - val_loss: 0.0111 - val_acc: 0.9737\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 513s 257ms/step - loss: 1.4553 - acc: 0.9687 - val_loss: 0.1147 - val_acc: 0.9747\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 513s 256ms/step - loss: 0.1578 - acc: 0.9698 - val_loss: 0.0524 - val_acc: 0.9743\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 513s 256ms/step - loss: 0.1346 - acc: 0.9696 - val_loss: 0.0046 - val_acc: 0.9657\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 512s 256ms/step - loss: 0.2673 - acc: 0.9666 - val_loss: 0.0057 - val_acc: 0.9686\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 512s 256ms/step - loss: 0.2018 - acc: 0.9666 - val_loss: 0.0130 - val_acc: 0.9657\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 512s 256ms/step - loss: 0.1727 - acc: 0.9668 - val_loss: 0.0784 - val_acc: 0.9720\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 494s 247ms/step - loss: 0.4584 - acc: 0.9612 - val_loss: 0.6966 - val_acc: 0.7034\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 492s 246ms/step - loss: 1.4428 - acc: 0.6919 - val_loss: 0.5144 - val_acc: 0.7480\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 492s 246ms/step - loss: 1.0442 - acc: 0.6876 - val_loss: 0.7933 - val_acc: 0.7183\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 492s 246ms/step - loss: 1.6324 - acc: 0.7132 - val_loss: 0.6028 - val_acc: 0.7331\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 492s 246ms/step - loss: 0.8397 - acc: 0.7268 - val_loss: 0.6183 - val_acc: 0.6109\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 491s 246ms/step - loss: 7.3081 - acc: 0.7065 - val_loss: 0.5786 - val_acc: 0.6730\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 492s 246ms/step - loss: 14286.3301 - acc: 0.7482 - val_loss: 0.6205 - val_acc: 0.7223\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 239.8742 - acc: 0.5266 - val_loss: 0.6966 - val_acc: 0.5017\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.7487 - acc: 0.4997 - val_loss: 0.6908 - val_acc: 0.5029\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6935 - acc: 0.4993 - val_loss: 0.6921 - val_acc: 0.5200\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6934 - acc: 0.5008 - val_loss: 0.7001 - val_acc: 0.4937\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6934 - acc: 0.5011 - val_loss: 0.6929 - val_acc: 0.5006\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6933 - acc: 0.4971 - val_loss: 0.6950 - val_acc: 0.4960\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6933 - acc: 0.4998 - val_loss: 0.6929 - val_acc: 0.4720\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6933 - acc: 0.4974 - val_loss: 0.6970 - val_acc: 0.5006\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6933 - acc: 0.5002 - val_loss: 0.6922 - val_acc: 0.5074\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 498s 249ms/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6944 - val_acc: 0.4857\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6907 - val_acc: 0.4960\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6928 - val_acc: 0.5057\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5025 - val_loss: 0.6941 - val_acc: 0.5143\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6898 - val_acc: 0.5149\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6922 - val_acc: 0.5011\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.4989\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6930 - val_acc: 0.4799\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5015 - val_loss: 0.6927 - val_acc: 0.4903\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6930 - val_acc: 0.5063\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6933 - val_acc: 0.4977\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6924 - val_acc: 0.5057\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6942 - val_acc: 0.4799\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6946 - val_acc: 0.4983\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5034\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6921 - val_acc: 0.4943\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4974 - val_loss: 0.6920 - val_acc: 0.5000\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6925 - val_acc: 0.4834\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5014 - val_loss: 0.6917 - val_acc: 0.4747\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.7005 - val_acc: 0.5074\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4964 - val_loss: 0.6929 - val_acc: 0.4909\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6936 - val_acc: 0.5109\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6922 - val_acc: 0.5057\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.5045 - val_loss: 0.6942 - val_acc: 0.5086\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6921 - val_acc: 0.5086\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4983 - val_loss: 0.6907 - val_acc: 0.4983\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.4969 - val_loss: 0.6916 - val_acc: 0.4983\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4983 - val_loss: 0.6902 - val_acc: 0.5109\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6943 - val_acc: 0.5011\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6933 - val_acc: 0.5006\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5011 - val_loss: 0.6953 - val_acc: 0.5103\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.5012 - val_loss: 0.6936 - val_acc: 0.4977\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 509s 254ms/step - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6929 - val_acc: 0.5091\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6932 - val_acc: 0.4823\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6942 - val_acc: 0.5057\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5015 - val_loss: 0.6931 - val_acc: 0.5017\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6937 - val_acc: 0.4926\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6954 - val_acc: 0.4914\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6956 - val_acc: 0.5051\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6961 - val_acc: 0.5177\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6957 - val_acc: 0.5023\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6950 - val_acc: 0.4856\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6933 - val_acc: 0.4937\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4970 - val_loss: 0.6940 - val_acc: 0.4977\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5223\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 492s 246ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6949 - val_acc: 0.4971\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 491s 246ms/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6928 - val_acc: 0.5006\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6942 - val_acc: 0.4908\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.5011\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5021 - val_loss: 0.6937 - val_acc: 0.5143\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6925 - val_acc: 0.5160\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6952 - val_acc: 0.5006\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6945 - val_acc: 0.4902\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6952 - val_acc: 0.4800\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6933 - val_acc: 0.5189\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6930 - val_acc: 0.5046\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6928 - val_acc: 0.5166\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6905 - val_acc: 0.4909\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6929 - val_acc: 0.4747\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5074\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4967 - val_loss: 0.6930 - val_acc: 0.4869\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6913 - val_acc: 0.4966\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6935 - val_acc: 0.5034\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4969 - val_loss: 0.6931 - val_acc: 0.4943\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5011\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4983 - val_loss: 0.6933 - val_acc: 0.5086\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5166\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6930 - val_acc: 0.5126\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.4971\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4967 - val_loss: 0.6960 - val_acc: 0.5086\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6937 - val_acc: 0.5120\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4976 - val_loss: 0.6918 - val_acc: 0.4954\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4969 - val_loss: 0.6922 - val_acc: 0.5006\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6938 - val_acc: 0.5057\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6935 - val_acc: 0.4954\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 490s 245ms/step - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.5178\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6935 - val_acc: 0.4994\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4978 - val_loss: 0.6930 - val_acc: 0.4966\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6862 - val_acc: 0.4926\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6934 - val_acc: 0.4903\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6979 - val_acc: 0.4879\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5015 - val_loss: 0.6912 - val_acc: 0.5051\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6930 - val_acc: 0.4886\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6942 - val_acc: 0.4709\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4974 - val_loss: 0.6920 - val_acc: 0.5057\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4962 - val_loss: 0.6932 - val_acc: 0.4937\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4974 - val_loss: 0.6939 - val_acc: 0.5052\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6935 - val_acc: 0.5040\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6931 - acc: 0.5043 - val_loss: 0.6945 - val_acc: 0.5074\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6965 - val_acc: 0.4971\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6951 - val_acc: 0.4966\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6924 - val_acc: 0.4925\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5031 - val_loss: 0.6925 - val_acc: 0.4840\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6935 - val_acc: 0.5063\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.5069\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6932 - val_acc: 0.5006\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6931 - acc: 0.5050 - val_loss: 0.6912 - val_acc: 0.5006\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5013 - val_loss: 0.6930 - val_acc: 0.4851\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6930 - val_acc: 0.5109\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 489s 245ms/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6928 - val_acc: 0.5109\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6930 - val_acc: 0.4914\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5024 - val_loss: 0.6939 - val_acc: 0.4966\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6906 - val_acc: 0.5211\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6934 - val_acc: 0.4885\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4971 - val_loss: 0.6925 - val_acc: 0.5074\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.4978 - val_loss: 0.6927 - val_acc: 0.5011\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6933 - val_acc: 0.5029\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.4983\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6901 - val_acc: 0.5000\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5008 - val_loss: 0.6950 - val_acc: 0.4897\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 488s 244ms/step - loss: 0.6931 - acc: 0.5037 - val_loss: 0.6921 - val_acc: 0.4994\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 489s 244ms/step - loss: 0.6932 - acc: 0.5017 - val_loss: 0.6930 - val_acc: 0.5046\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 493s 246ms/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6919 - val_acc: 0.4983\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.5080\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 506s 253ms/step - loss: 0.6932 - acc: 0.4978 - val_loss: 0.6935 - val_acc: 0.4920\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 506s 253ms/step - loss: 0.6932 - acc: 0.4969 - val_loss: 0.6926 - val_acc: 0.5223\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 506s 253ms/step - loss: 0.6932 - acc: 0.4975 - val_loss: 0.6934 - val_acc: 0.5166\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 506s 253ms/step - loss: 0.6932 - acc: 0.5034 - val_loss: 0.6937 - val_acc: 0.4789\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 508s 254ms/step - loss: 0.6932 - acc: 0.5038 - val_loss: 0.6920 - val_acc: 0.5103\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 506s 253ms/step - loss: 0.6932 - acc: 0.5022 - val_loss: 0.6912 - val_acc: 0.4937\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6944 - val_acc: 0.5167\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 507s 254ms/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6935 - val_acc: 0.5029\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6924 - val_acc: 0.4823\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6912 - val_acc: 0.4897\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6926 - val_acc: 0.5040\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6921 - val_acc: 0.5029\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000, #每个step表示1个batch_size的数据大小\n",
    "        epochs=200,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc =  history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
